{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Training Neural Network( optimizer, grad,loss,MNIST).ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"P1SzOa5cOsox","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch import optim\n","\n","# Define a transform to normalize the data\n","transform = transforms.Compose([transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                              ])\n","# Download and load the training data\n","trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cJDuR5dhPZv0","colab_type":"code","outputId":"fbc916a1-3166-4a63-b017-18d7d6f54dc2","executionInfo":{"status":"ok","timestamp":1543264962740,"user_tz":480,"elapsed":52793,"user":{"displayName":"Ritul Patidar","photoUrl":"https://lh4.googleusercontent.com/-FN-NHp32ujY/AAAAAAAAAAI/AAAAAAAAAGg/NYELu2XQ7Lk/s64/photo.jpg","userId":"11865105037108873448"}},"colab":{"base_uri":"https://localhost:8080/","height":108}},"cell_type":"code","source":["model = nn.Sequential(nn.Linear(784, 128),\n","                      nn.ReLU(),\n","                      nn.Linear(128, 64),\n","                      nn.ReLU(),\n","                      nn.Linear(64, 10),\n","                      nn.LogSoftmax(dim=1))\n","\n","criterion = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.003)\n","\n","epochs = 5\n","for e in range(epochs):\n","    running_loss = 0\n","    for images, labels in trainloader:\n","        # Flatten MNIST images into a 784 long vector\n","        images = images.view(images.shape[0], -1)\n","    \n","        # Training pass\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        # Take an update step and few the new weights\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","    else:\n","        print(f\"Training loss: {running_loss/len(trainloader)}\")"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Training loss: 1.9096296007699296\n","Training loss: 0.8672786320069197\n","Training loss: 0.5345440972874413\n","Training loss: 0.4326678121299632\n","Training loss: 0.3848142408962443\n"],"name":"stdout"}]},{"metadata":{"id":"7JCOqKL3QFiF","colab_type":"code","colab":{}},"cell_type":"code","source":["%matplotlib inline\n","import helper\n","\n","images, labels = next(iter(trainloader))\n","\n","img = images[0].view(1, 784)\n","# Turn off gradients to speed up this part\n","with torch.no_grad():\n","    logps = model(img)\n","\n","# Output of the network are log-probabilities, need to take exponential for probabilities\n","ps = torch.exp(logps)\n","helper.view_classify(img.view(1, 28, 28), ps)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PMoJ3LEtTatm","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}